{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxe/eYSRHQCSgdvtTv13CP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rci27/AI/blob/main/Copy_of_Ron_RR_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O-XR4oTk2d5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "qnvuOaS62rK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file\n",
        "data = pd.read_excel('/content/rrtest2.xlsx') # Use pd.read_excel to read Excel files\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(data.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IEkKQkRj293v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine relevant textual columns into a single column\n",
        "data['combined_text'] = data['Task'] + ' ' + data['Responsibility'] + ' ' + data['Remarks']"
      ],
      "metadata": {
        "id": "oveXJmZ03Cw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Fill missing values in 'combined_text' with an empty string\n",
        "data['combined_text'] = data['combined_text'].fillna('')\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Convert textual data into numerical features using TF-IDF\n",
        "X = vectorizer.fit_transform(data['combined_text'])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8QSb42Nc3Nr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['Identifier'] # Replace 'Target_Variable' with the actual target column name if applicable"
      ],
      "metadata": {
        "id": "MdKGI3IF3XJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nMvRCQ-F3c-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(10,)))  # Define input layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# ... other layers"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Ue_6S-ep3rII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np # Import NumPy\n",
        "\n",
        "# Determine the correct input shape\n",
        "input_shape = X_train.shape[1]\n",
        "\n",
        "# Encode string labels to numerical categories\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit on all unique labels from both training and testing data to handle unseen labels\n",
        "all_labels = np.unique(np.concatenate((y_train, y_test), axis=0))\n",
        "label_encoder.fit(all_labels)\n",
        "\n",
        "y_train_encoded = label_encoder.transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# One-hot encode your target variable\n",
        "y_train_encoded = to_categorical(y_train_encoded)\n",
        "\n",
        "# Make sure y_test_encoded has the same number of classes as y_train_encoded\n",
        "y_test_encoded = to_categorical(y_test_encoded, num_classes=y_train_encoded.shape[1])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(input_shape,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# ... other layers\n",
        "\n",
        "# Adjust the number of units in the output layer to match the number of classes\n",
        "num_classes = y_train_encoded.shape[1]\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train_encoded, epochs=100, batch_size=32, validation_data=(X_test, y_test_encoded))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "nKOY8j1S6G-8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# One-hot encode y_test, ensuring it has the same number of classes as the model's output\n",
        "y_test_encoded = to_categorical(label_encoder.transform(y_test), num_classes=model.output_shape[1])\n",
        "\n",
        "# Evaluate the model with the one-hot encoded test labels\n",
        "loss, accuracy = model.evaluate(X_test, y_test_encoded)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "mnQ-JJyO6xJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = pd.DataFrame({'Task': ['New task'], 'Responsibility': ['New responsibility'], 'Remarks': ['New remarks']}) # Example new data\n",
        "new_data['combined_text'] = new_data['Task'] + ' ' + new_data['Responsibility'] + ' ' + new_data['Remarks']\n",
        "new_features = vectorizer.transform(new_data['combined_text'])\n",
        "predictions = model.predict(new_features)\n",
        "print('Predictions:', predictions)"
      ],
      "metadata": {
        "id": "0WCHNk3461-n",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import google.generativeai as palm\n",
        "palm.configure(api_key='AIzaSyBVFFxicQhd2ktbEshxZJLhoEIYBsTEt1c') # Replace with your actual API key"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "f1duj10-FHG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import google.generativeai as palm\n",
        "\n",
        "# Replace with your actual API key\n",
        "palm.configure(api_key='AIzaSyBVFFxicQhd2ktbEshxZJLhoEIYBsTEt1c')\n",
        "\n",
        "def generate_olympic_medal_report(country):\n",
        "    prompt = f\"Give me a short report on {country}'s medal performance at the 2024 Olympics. Provide only the total medal count.\"\n",
        "    response = palm.generate_text(\n",
        "        model='models/text-bison-001',\n",
        "        prompt=prompt\n",
        "    )\n",
        "    return \"To date, \" + response.result  # Add \"To date, \" to the beginning\n",
        "\n",
        "# Example usage\n",
        "country = input(\"Please enter the name of your favorite country: \")\n",
        "medal_report = generate_olympic_medal_report(country)\n",
        "print(medal_report)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "G2zJrzq179AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import google.generativeai as palm # Import for generative AI\n",
        "\n",
        "# Configure PaLM API (replace with your actual API key)\n",
        "palm.configure(api_key='AIzaSyBVFFxicQhd2ktbEshxZJLhoEIYBsTEt1c')\n",
        "\n",
        "def predict_top_identifiers_with_explanation(question, model, vectorizer, label_encoder, data, top_n=3):\n",
        "    \"\"\"\n",
        "    Predicts the top N identifiers for a given question.\n",
        "    Includes relevant remarks, responsibility, and task for the top prediction.\n",
        "\n",
        "    Args:\n",
        "        question (str): The question to predict identifiers for.\n",
        "        model: The trained Keras model.\n",
        "        vectorizer: The TfidfVectorizer used to transform the question.\n",
        "        label_encoder: The LabelEncoder used to encode/decode identifiers.\n",
        "        data (DataFrame): The original DataFrame containing 'Identifier', 'Task', 'Responsibility', and 'Remarks' columns.\n",
        "        top_n (int): The number of top identifiers to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each containing the predicted identifier, its probability,\n",
        "              and remarks, responsibility, and task for the top one.\n",
        "    \"\"\"\n",
        "\n",
        "    # Transform the question using the same vectorizer used for training\n",
        "    question_tfidf = vectorizer.transform([question])\n",
        "\n",
        "    # Check if question_tfidf is empty and handle the case\n",
        "    if question_tfidf.shape[1] == 0:\n",
        "        print(\"Warning: The vectorized question is empty. Check your vectorizer and input.\")\n",
        "        return []  # Return an empty list to indicate no predictions\n",
        "\n",
        "    # Predict probabilities for the question\n",
        "    y_pred_probs = model.predict(question_tfidf)\n",
        "\n",
        "    # Get the indices of the top N predicted classes\n",
        "    top_n_pred_indices = np.argsort(y_pred_probs, axis=1)[:, -top_n:][:, ::-1]\n",
        "\n",
        "    # Decode the indices back to original labels\n",
        "    top_n_pred_labels = label_encoder.inverse_transform(top_n_pred_indices.flatten()).reshape(top_n_pred_indices.shape)\n",
        "\n",
        "    results = []\n",
        "    for i in range(top_n):\n",
        "        identifier = top_n_pred_labels[0][i]\n",
        "        probability = y_pred_probs[0][top_n_pred_indices[0][i]]\n",
        "\n",
        "        result_dict = {\n",
        "            'identifier': identifier,\n",
        "            'probability': probability,\n",
        "        }\n",
        "\n",
        "        # Add remarks, responsibility, and task for the top prediction\n",
        "        if i == 0:\n",
        "            remarks = data[data['Identifier'] == identifier]['Remarks'].values\n",
        "            responsibility = data[data['Identifier'] == identifier]['Responsibility'].values\n",
        "            task = data[data['Identifier'] == identifier]['Task'].values\n",
        "            if remarks.size > 0:\n",
        "                if remarks[0] == \".\":  # Check if remarks is just a period\n",
        "                    result_dict['remarks'] = \"Sorry, there are no remarks for this item.\"\n",
        "                else:\n",
        "                    result_dict['remarks'] = remarks[0]\n",
        "            if responsibility.size > 0:\n",
        "                result_dict['responsibility'] = \"This is a(n) \" + responsibility[0]\n",
        "            if task.size > 0:\n",
        "                result_dict['task'] = task[0]\n",
        "                result_dict['task'] = task[0]\n",
        "\n",
        "        results.append(result_dict)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage (assuming you have the model, vectorizer, label_encoder, and data available):\n",
        "question = input(\"Enter your question: \")\n",
        "top_identifiers_with_explanations = predict_top_identifiers_with_explanation(question, model, vectorizer, label_encoder, data)\n",
        "\n",
        "for result in top_identifiers_with_explanations:\n",
        "    print() # Add a line break here\n",
        "    print(f\"Identifier: {result['identifier']}, Probability: {result['probability']:.4f}\")\n",
        "    print() # Add a line break here\n",
        "    if 'task' in result:\n",
        "        print(f\"Task: {result['task']}\")\n",
        "        print() # Add a line break here\n",
        "    if 'remarks' in result:\n",
        "        print(f\"Remarks: {result['remarks']}\")\n",
        "        print() # Add a line break here\n",
        "    if 'responsibility' in result:\n",
        "        print(f\"Responsibility: {result['responsibility']}\")\n",
        "        print() # Add a line break here\n",
        "\n",
        "# Generate a poem based on the task\n",
        "        prompt = f\"Write a concise definition based on this R&R task and remarks by cross-referencing information about SAP, SAP services, SAP functions, SAP maintenance:\\nTask: {result['task']}\\nRemarks: {result['remarks']}\"\n",
        "        response = palm.generate_text(model='models/text-bison-001', prompt=prompt)\n",
        "        print(\"Here is a wild guess as to the general concept of this task:\\n\", response.result)\n",
        "        print()\n",
        "\n",
        "# Generate a poem based on the task\n",
        "        prompt = f\"Write a short poem about this R&R task from the context of an SAP expert. The poem should not exceed 8 lines: {result['task']}\\nRemarks: {result['remarks']}\"\n",
        "        response = palm.generate_text(model='models/text-bison-001', prompt=prompt)\n",
        "        print(\"The R&R can be pure poetry!:\\n\", response.result)\n",
        "        print()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "AcIsBUJA3K5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p73KAUDREWmE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}